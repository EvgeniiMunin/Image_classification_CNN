{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "# import necessary building blocks for CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images, convert to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(27, 960, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "images = []\n",
    "for image_path in glob.glob(\"C:/Users/mvideo/Documents/Fax/data_2images_v2_27im/*.jpg\"):\n",
    "    #print(image.shape)\n",
    "    #print(image.dtype)\n",
    "    # put into np.array\n",
    "    image = misc.imread(image_path)\n",
    "    images.append(np.asarray( image, dtype=\"int32\" ))\n",
    "    # visualize images\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "X = np.concatenate([image[np.newaxis] for image in images])\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "# (960, 1280, 3) 960, 1280 - количество пикселей. 3- rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Read the names of the files into y y.shape = (71,1).\n",
    "labels = []\n",
    "for image_path in glob.glob(\"C:/Users/mvideo/Documents/Fax/data_2images_v2_27im/*.jpg\"):\n",
    "    temp = str(image_path)[52:]\n",
    "    temp = temp[:-6]\n",
    "    temp = re.sub('_', '', temp)\n",
    "    labels.append(int(temp))\n",
    "y = np.asarray([x-1 for x in labels])\n",
    "#y = [x-1 for x in y]\n",
    "print(type(y))\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crop images from 960*1280 to 400*400\n",
    "IMG_SIZE = 400\n",
    "crop_coord1 = int(0.5*(X.shape[1] - IMG_SIZE))\n",
    "crop_coord2 = int(0.5*(X.shape[2] - IMG_SIZE))\n",
    "X_crop = X[:,crop_coord1:(crop_coord1+IMG_SIZE),crop_coord2:(crop_coord2+IMG_SIZE),:]\n",
    "#cropped_img = slice1[:,crop_coord2:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaly to train model we need dozens of thousands of images\n",
    "Train samples: (50000, 32, 32, 3) (50000, 1)\n",
    "Test samples: (10000, 32, 32, 3) (10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Normalize inputs. \n",
    "COnvert class labels to one-hot encoded vectors. Use keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape image to normalize it in Standard Scaler (2d only authorized)\n",
    "#X_resh = X_crop.reshape((2,IMG_SIZE*IMG_SIZE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs\n",
    "X_red = X_crop/255\n",
    "y_cat = to_categorical(y, num_classes=len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 400, 400, 3)   (21, 3)\n",
      "(6, 400, 400, 3)   (6, 3)\n"
     ]
    }
   ],
   "source": [
    "# SPlit the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_red, y_cat, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,' ',y_train.shape)\n",
    "print(X_val.shape,' ',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "    # 1st conv \n",
    "    model.add(Conv2D(16,(3,3),padding=\"same\",activation='relu', input_shape=(400, 400, 3)))  # first layer needs to define \"input_shape\"\n",
    "    model.add(BatchNormalization(axis=1)) # accelerate training\n",
    "    model.add(LeakyReLU(0.1))\n",
    "\n",
    "    # 2nd conv\n",
    "    model.add(Conv2D(32,(3,3),padding=\"same\",activation='relu')) \n",
    "    model.add(BatchNormalization(axis=1)) # accelerate training\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 3rd conv\n",
    "    model.add(Conv2D(32,(3,3),padding=\"same\",activation='relu'))  \n",
    "    model.add(BatchNormalization(axis=1)) # accelerate training\n",
    "    model.add(LeakyReLU(0.1))\n",
    "\n",
    "    # 4rd conv\n",
    "    model.add(Conv2D(64,(3,3),padding=\"same\",activation='relu'))  \n",
    "    model.add(BatchNormalization(axis=1)) # accelerate training\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 1st dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 2nd dense layer\n",
    "    model.add(Dense(len(np.unique(y))))  # the last layer with neuron for each class\n",
    "    model.add(Activation(\"softmax\"))  # output probabilities\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 400, 400, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 400, 400, 16)      1600      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 400, 400, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 400, 400, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 400, 400, 32)      1600      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 400, 400, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 200, 200, 32)      800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 200, 200, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200, 200, 64)      800       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 200, 200, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               163840256 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 163,878,659\n",
      "Trainable params: 163,876,259\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe model\n",
    "#clear_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continue to train model from checkpoint\n",
    "from keras.models import load_model\n",
    "#from keras.utils import ModelSaveCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 5\n",
    "model = make_model()  # define our model\n",
    "last_finished_epoch = None\n",
    "num_epochs = 25\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer='sgd',  # for SGD\n",
    "    metrics=['mae', 'acc']  # report accuracy during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 6 samples\n",
      "Epoch 1/25\n",
      "21/21 [==============================] - 97s 5s/step - loss: 4.3793 - mean_absolute_error: 0.2222 - acc: 0.6667 - val_loss: 2.6863 - val_mean_absolute_error: 0.1111 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00001: saving model to weights.01-0.83.hdf5\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 85s 4s/step - loss: 6.1402 - mean_absolute_error: 0.2540 - acc: 0.6190 - val_loss: 2.6863 - val_mean_absolute_error: 0.1111 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00002: saving model to weights.02-0.83.hdf5\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 87s 4s/step - loss: 6.1402 - mean_absolute_error: 0.2540 - acc: 0.6190 - val_loss: 2.6863 - val_mean_absolute_error: 0.1111 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00003: saving model to weights.03-0.83.hdf5\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 82s 4s/step - loss: 5.6638 - mean_absolute_error: 0.2540 - acc: 0.6190 - val_loss: 1.1921e-07 - val_mean_absolute_error: 2.3212e-09 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: saving model to weights.04-1.00.hdf5\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 83s 4s/step - loss: 1.7010 - mean_absolute_error: 0.0943 - acc: 0.8571 - val_loss: 1.1921e-07 - val_mean_absolute_error: 1.9765e-16 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: saving model to weights.05-1.00.hdf5\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 81s 4s/step - loss: 3.1066e-04 - mean_absolute_error: 2.0670e-04 - acc: 1.0000 - val_loss: 1.1921e-07 - val_mean_absolute_error: 1.0309e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: saving model to weights.06-1.00.hdf5\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 82s 4s/step - loss: 1.8436 - mean_absolute_error: 0.1013 - acc: 0.8571 - val_loss: 1.3918 - val_mean_absolute_error: 0.1111 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00007: saving model to weights.07-0.83.hdf5\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 82s 4s/step - loss: 2.1089 - mean_absolute_error: 0.0952 - acc: 0.8571 - val_loss: 1.1921e-07 - val_mean_absolute_error: 4.7940e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: saving model to weights.08-1.00.hdf5\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 83s 4s/step - loss: 1.5351 - mean_absolute_error: 0.0635 - acc: 0.9048 - val_loss: 1.1921e-07 - val_mean_absolute_error: 4.0315e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00009: saving model to weights.09-1.00.hdf5\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.7675 - mean_absolute_error: 0.0317 - acc: 0.9524 - val_loss: 1.1921e-07 - val_mean_absolute_error: 1.7733e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00010: saving model to weights.10-1.00.hdf5\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.7675 - mean_absolute_error: 0.0317 - acc: 0.9524 - val_loss: 1.1921e-07 - val_mean_absolute_error: 3.6298e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00011: saving model to weights.11-1.00.hdf5\n",
      "Epoch 12/25\n",
      "21/21 [==============================] - 81s 4s/step - loss: 0.7675 - mean_absolute_error: 0.0317 - acc: 0.9524 - val_loss: 1.1921e-07 - val_mean_absolute_error: 1.7354e-17 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00012: saving model to weights.12-1.00.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b23d69e668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import utils as np_utils\n",
    "# fit model\n",
    "model.fit(\n",
    "    X_train, y_train,  # prepared data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=num_epochs,\n",
    "    callbacks = [ModelCheckpoint('weights.{epoch:02d}-{val_acc:.2f}.hdf5',\n",
    "                                monitor='val_loss', verbose=1, \n",
    "                                save_best_only=False, \n",
    "                                save_weights_only=False, \n",
    "                                mode='auto', \n",
    "                                period=1),\n",
    "                EarlyStopping(monitor='val_loss', patience=8)],\n",
    "    validation_data=(X_val, y_val),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch or 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights to file\n",
    "model.save_weights('weights_27images.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights from file (can be called without model.fit)\n",
    "model.load_weights('weights_27images.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
